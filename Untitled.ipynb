{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d4de81b9-e9b8-4e09-8a28-20ccdab7e718",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'sklearn.tree._classes.DecisionTreeClassifier'>\n",
      "DecisionTreeClassifier(max_depth=5, random_state=42)\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "# Ruta al archivo .pkl\n",
    "file_path = 'modelo_arbol_decision.pkl'\n",
    "\n",
    "# Cargar el modelo\n",
    "with open(file_path, 'rb') as file:\n",
    "    model = pickle.load(file)\n",
    "\n",
    "# Ver el tipo de modelo y su configuración\n",
    "print(type(model))\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2f551234-aea7-4c10-ac6d-4bf69d842155",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Importancia de características: [0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "print(\"Importancia de características:\", model.feature_importances_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f66abd03-7684-44ca-8d95-a35e04ffe604",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clases aprendidas: [0]\n"
     ]
    }
   ],
   "source": [
    "print(\"Clases aprendidas:\", model.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ac79e6a0-ddcb-463d-9088-26c68d410c31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicción para datos de prueba: [0]\n"
     ]
    }
   ],
   "source": [
    "# Ejemplo de datos de entrada (ajusta los valores según las características de tu modelo)\n",
    "test_data = [[1, 2, 3]]  # Cambia estos valores a los adecuados\n",
    "\n",
    "# Realizar una predicción\n",
    "prediccion = model.predict(test_data)\n",
    "print(\"Predicción para datos de prueba:\", prediccion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "238e9e9c-701e-4aaa-be01-bbd32184cff8",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDatos de entrenamiento X:\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[43mX\u001b[49m)\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDatos de entrenamiento y:\u001b[39m\u001b[38;5;124m\"\u001b[39m, y)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'X' is not defined"
     ]
    }
   ],
   "source": [
    "print(\"Datos de entrenamiento X:\", X)\n",
    "print(\"Datos de entrenamiento y:\", y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "81c50b56-d8b2-488e-b1e2-7d1c27339b0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datos X (complejo): [[1 1 0]\n",
      " [2 1 1]\n",
      " [5 4 1]\n",
      " [2 1 1]\n",
      " [5 1 0]\n",
      " [3 4 1]\n",
      " [5 2 0]\n",
      " [2 4 0]\n",
      " [4 1 1]\n",
      " [4 1 1]\n",
      " [2 2 0]\n",
      " [5 1 0]\n",
      " [4 3 1]\n",
      " [3 3 1]\n",
      " [4 5 1]\n",
      " [2 3 0]\n",
      " [5 5 0]\n",
      " [4 4 1]\n",
      " [5 5 0]\n",
      " [5 5 0]\n",
      " [2 3 0]\n",
      " [5 1 1]\n",
      " [4 1 0]\n",
      " [1 2 1]\n",
      " [4 1 1]\n",
      " [3 2 0]\n",
      " [5 3 1]\n",
      " [4 3 1]\n",
      " [1 4 0]\n",
      " [5 1 1]\n",
      " [4 4 0]\n",
      " [1 2 1]\n",
      " [4 2 1]\n",
      " [2 4 0]\n",
      " [4 3 0]\n",
      " [5 2 0]\n",
      " [4 1 0]\n",
      " [5 3 1]\n",
      " [4 1 1]\n",
      " [1 4 0]\n",
      " [1 3 1]\n",
      " [2 3 0]\n",
      " [3 4 0]\n",
      " [1 3 0]\n",
      " [2 4 1]\n",
      " [5 2 0]\n",
      " [2 2 0]\n",
      " [5 5 1]\n",
      " [5 5 0]\n",
      " [4 3 0]\n",
      " [2 1 1]\n",
      " [3 1 0]\n",
      " [5 4 1]\n",
      " [4 2 0]\n",
      " [2 2 0]\n",
      " [4 1 0]\n",
      " [2 5 1]\n",
      " [3 2 0]\n",
      " [2 3 1]\n",
      " [1 5 1]\n",
      " [4 3 1]\n",
      " [5 3 0]\n",
      " [3 3 0]\n",
      " [5 2 1]\n",
      " [1 3 1]\n",
      " [3 5 1]\n",
      " [5 4 0]\n",
      " [2 2 0]\n",
      " [5 3 1]\n",
      " [2 2 1]\n",
      " [2 3 0]\n",
      " [4 3 1]\n",
      " [4 5 0]\n",
      " [4 5 0]\n",
      " [5 3 1]\n",
      " [1 5 1]\n",
      " [3 3 1]\n",
      " [1 4 0]\n",
      " [3 2 0]\n",
      " [1 3 1]\n",
      " [1 5 0]\n",
      " [5 5 0]\n",
      " [2 5 1]\n",
      " [2 4 0]\n",
      " [5 5 1]\n",
      " [3 4 0]\n",
      " [5 4 1]\n",
      " [4 2 0]\n",
      " [4 4 1]\n",
      " [2 1 0]\n",
      " [1 5 1]\n",
      " [2 5 0]\n",
      " [1 2 0]\n",
      " [5 4 0]\n",
      " [5 5 0]\n",
      " [1 4 1]\n",
      " [5 4 1]\n",
      " [1 3 0]\n",
      " [5 4 0]\n",
      " [1 3 0]\n",
      " [2 2 1]\n",
      " [4 1 0]\n",
      " [5 1 0]\n",
      " [5 1 1]\n",
      " [2 4 1]\n",
      " [2 4 0]\n",
      " [1 5 0]\n",
      " [5 1 0]\n",
      " [5 3 0]\n",
      " [1 1 1]\n",
      " [5 2 1]\n",
      " [5 4 0]\n",
      " [3 2 0]\n",
      " [5 1 1]\n",
      " [2 3 0]\n",
      " [1 3 0]\n",
      " [3 1 0]\n",
      " [2 5 0]\n",
      " [5 3 1]\n",
      " [1 1 0]\n",
      " [1 3 0]\n",
      " [4 2 0]\n",
      " [1 5 1]\n",
      " [4 2 0]\n",
      " [5 3 0]\n",
      " [3 1 0]\n",
      " [2 3 0]\n",
      " [5 1 1]\n",
      " [5 2 0]\n",
      " [5 3 1]\n",
      " [5 2 0]\n",
      " [4 1 0]\n",
      " [5 4 1]\n",
      " [2 1 0]\n",
      " [3 4 0]\n",
      " [2 1 1]\n",
      " [2 2 0]\n",
      " [4 1 1]\n",
      " [1 1 1]\n",
      " [3 5 0]\n",
      " [2 2 0]\n",
      " [2 1 1]\n",
      " [4 2 1]\n",
      " [4 3 0]\n",
      " [5 1 0]\n",
      " [1 2 0]\n",
      " [1 1 1]\n",
      " [4 4 0]\n",
      " [2 1 0]\n",
      " [2 1 1]\n",
      " [2 5 0]\n",
      " [4 1 1]\n",
      " [3 1 0]\n",
      " [1 5 0]\n",
      " [3 1 0]\n",
      " [3 5 0]\n",
      " [3 2 1]\n",
      " [4 5 1]\n",
      " [1 1 0]\n",
      " [3 1 0]\n",
      " [5 2 1]\n",
      " [4 5 1]\n",
      " [1 2 1]\n",
      " [5 1 0]\n",
      " [1 3 0]\n",
      " [2 5 1]\n",
      " [1 1 1]\n",
      " [5 1 1]\n",
      " [4 2 0]\n",
      " [1 1 1]\n",
      " [2 5 1]\n",
      " [4 5 1]\n",
      " [1 3 0]\n",
      " [2 3 1]\n",
      " [5 2 1]\n",
      " [3 5 0]\n",
      " [3 5 1]\n",
      " [2 5 1]\n",
      " [2 4 1]\n",
      " [3 1 1]\n",
      " [4 3 0]\n",
      " [5 5 1]\n",
      " [5 5 0]\n",
      " [4 2 0]\n",
      " [1 5 1]\n",
      " [5 2 0]\n",
      " [5 2 0]\n",
      " [5 2 1]\n",
      " [4 1 0]\n",
      " [5 5 1]\n",
      " [5 3 1]\n",
      " [2 5 0]\n",
      " [5 2 0]\n",
      " [2 3 1]\n",
      " [4 5 0]\n",
      " [5 2 1]\n",
      " [1 4 1]\n",
      " [2 3 1]\n",
      " [4 1 1]\n",
      " [5 2 1]]\n",
      "Datos y (complejo): [17 38 26 35 10  6 33 20 43 36  2 35  4  3 40  8 20  3 20 32 12 19 45 31\n",
      " 34 10 25  1 38  2 14  8 41  4 25 10  4 13 34  7  5 19  5 31 11 26 41 10\n",
      " 16 25  4  8 24  8 23 16 32 17 42 25 31 34 17 15 19 32 27  4 43 22 25 12\n",
      " 26 39 38 31 45 41 14 11 39 39 37 26 41 35 11 42 41  6 21  3 25 27 17 30\n",
      " 37 31 26 11 44 41 11 11  6 27 28 12  2 36 31  3 33  9 39 19 15 18 34 40\n",
      " 22 40 44 40 25 30 26  6  2 30  6 23 20 16  2  3 36 35  3 21 44 26 22 27\n",
      " 38 44 43 18  8 30 34  1 39 33 23 40 44 36 40 32 22 22 23 30 17 44 32 22\n",
      " 32 17 20 25 27 45  6 42 36 26 19 10 22 20 19 40 26  2 38  9  2 29 13 27\n",
      "  9 37  5  5  7 15 11 21]\n",
      "Datos X (dinamico): [[5 2 1]\n",
      " [4 2 0]\n",
      " [5 2 1]\n",
      " [4 1 0]\n",
      " [1 1 0]\n",
      " [5 4 1]\n",
      " [4 3 1]\n",
      " [3 3 1]\n",
      " [3 2 1]\n",
      " [1 5 0]\n",
      " [4 1 0]\n",
      " [3 4 1]\n",
      " [5 1 0]\n",
      " [2 3 0]\n",
      " [5 2 0]\n",
      " [2 5 0]\n",
      " [5 1 0]\n",
      " [5 1 0]\n",
      " [3 1 0]\n",
      " [1 5 1]\n",
      " [1 2 1]\n",
      " [5 4 0]\n",
      " [3 5 0]\n",
      " [3 3 1]\n",
      " [5 2 1]\n",
      " [2 2 1]\n",
      " [4 3 0]\n",
      " [4 1 0]\n",
      " [1 1 0]\n",
      " [4 2 0]\n",
      " [3 3 0]\n",
      " [4 2 0]\n",
      " [5 3 0]\n",
      " [3 1 0]\n",
      " [3 3 1]\n",
      " [5 1 0]\n",
      " [4 3 0]\n",
      " [2 1 0]\n",
      " [4 4 0]\n",
      " [4 4 1]\n",
      " [3 4 0]\n",
      " [1 1 1]\n",
      " [1 1 0]\n",
      " [4 4 1]\n",
      " [2 2 0]\n",
      " [4 3 1]\n",
      " [4 2 0]\n",
      " [1 1 0]\n",
      " [1 4 1]\n",
      " [5 3 0]\n",
      " [5 4 1]\n",
      " [3 4 0]\n",
      " [2 2 0]\n",
      " [3 5 0]\n",
      " [5 2 0]\n",
      " [4 4 1]\n",
      " [4 3 0]\n",
      " [3 4 1]\n",
      " [5 4 1]\n",
      " [2 4 1]\n",
      " [3 1 1]\n",
      " [4 2 1]\n",
      " [4 3 0]\n",
      " [5 1 0]\n",
      " [3 1 1]\n",
      " [5 2 1]\n",
      " [4 5 0]\n",
      " [4 2 0]\n",
      " [2 2 0]\n",
      " [3 5 1]\n",
      " [2 1 0]\n",
      " [5 3 0]\n",
      " [4 1 1]\n",
      " [5 3 0]\n",
      " [5 5 0]\n",
      " [4 1 0]\n",
      " [1 4 0]\n",
      " [5 5 0]\n",
      " [4 1 0]\n",
      " [4 4 0]\n",
      " [3 2 1]\n",
      " [4 5 0]\n",
      " [1 5 0]\n",
      " [5 1 0]\n",
      " [4 4 1]\n",
      " [5 4 1]\n",
      " [5 1 0]\n",
      " [1 5 1]\n",
      " [5 5 0]\n",
      " [4 4 0]\n",
      " [2 4 0]\n",
      " [2 2 1]\n",
      " [2 2 0]\n",
      " [5 4 0]\n",
      " [2 3 0]\n",
      " [2 4 1]\n",
      " [3 4 1]\n",
      " [4 1 1]\n",
      " [1 3 1]\n",
      " [1 5 1]]\n",
      "Datos y (dinamico): ['Baja prioridad' 'Baja prioridad' 'Baja prioridad' 'Baja prioridad'\n",
      " 'Baja prioridad' 'Alta prioridad' 'Media prioridad' 'Media prioridad'\n",
      " 'Baja prioridad' 'Baja prioridad' 'Baja prioridad' 'Media prioridad'\n",
      " 'Baja prioridad' 'Baja prioridad' 'Baja prioridad' 'Baja prioridad'\n",
      " 'Baja prioridad' 'Baja prioridad' 'Baja prioridad' 'Baja prioridad'\n",
      " 'Baja prioridad' 'Alta prioridad' 'Media prioridad' 'Media prioridad'\n",
      " 'Baja prioridad' 'Baja prioridad' 'Media prioridad' 'Baja prioridad'\n",
      " 'Baja prioridad' 'Baja prioridad' 'Media prioridad' 'Baja prioridad'\n",
      " 'Media prioridad' 'Baja prioridad' 'Media prioridad' 'Baja prioridad'\n",
      " 'Media prioridad' 'Baja prioridad' 'Alta prioridad' 'Alta prioridad'\n",
      " 'Media prioridad' 'Baja prioridad' 'Baja prioridad' 'Alta prioridad'\n",
      " 'Baja prioridad' 'Media prioridad' 'Baja prioridad' 'Baja prioridad'\n",
      " 'Baja prioridad' 'Media prioridad' 'Alta prioridad' 'Media prioridad'\n",
      " 'Baja prioridad' 'Media prioridad' 'Baja prioridad' 'Alta prioridad'\n",
      " 'Media prioridad' 'Media prioridad' 'Alta prioridad' 'Baja prioridad'\n",
      " 'Baja prioridad' 'Baja prioridad' 'Media prioridad' 'Baja prioridad'\n",
      " 'Baja prioridad' 'Baja prioridad' 'Alta prioridad' 'Baja prioridad'\n",
      " 'Baja prioridad' 'Media prioridad' 'Baja prioridad' 'Media prioridad'\n",
      " 'Baja prioridad' 'Media prioridad' 'Alta prioridad' 'Baja prioridad'\n",
      " 'Baja prioridad' 'Alta prioridad' 'Baja prioridad' 'Alta prioridad'\n",
      " 'Baja prioridad' 'Alta prioridad' 'Baja prioridad' 'Baja prioridad'\n",
      " 'Alta prioridad' 'Alta prioridad' 'Baja prioridad' 'Baja prioridad'\n",
      " 'Alta prioridad' 'Alta prioridad' 'Baja prioridad' 'Baja prioridad'\n",
      " 'Baja prioridad' 'Alta prioridad' 'Baja prioridad' 'Baja prioridad'\n",
      " 'Media prioridad' 'Baja prioridad' 'Baja prioridad' 'Baja prioridad']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Cargar el CSV\n",
    "df_complejo = pd.read_csv(\"conjunto_datos_tareas_complejo.csv\")\n",
    "df_dinamico = pd.read_csv(\"conjunto_datos_tareas_dinamico.csv\")\n",
    "\n",
    "# Selecciona las características y la etiqueta\n",
    "# (Ajusta las columnas según los datos que tienes en tus CSV)\n",
    "X_complejo = df_complejo[['urgencia', 'importancia', 'prioridad_externa']].values\n",
    "y_complejo = df_complejo['dias_restantes'].values\n",
    "\n",
    "X_dinamico = df_dinamico[['urgencia', 'importancia', 'prioridad_externa']].values\n",
    "y_dinamico = df_dinamico['clasificacion'].values  # Asegúrate de que esta columna es la correcta\n",
    "\n",
    "# Imprimir los datos para revisar\n",
    "print(\"Datos X (complejo):\", X_complejo)\n",
    "print(\"Datos y (complejo):\", y_complejo)\n",
    "\n",
    "print(\"Datos X (dinamico):\", X_dinamico)\n",
    "print(\"Datos y (dinamico):\", y_dinamico)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "24efb5c0-4ddb-4e4a-ae59-8aa675c95d51",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'<' not supported between instances of 'int' and 'str'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 13\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m# Crear y entrenar el modelo\u001b[39;00m\n\u001b[0;32m     12\u001b[0m model \u001b[38;5;241m=\u001b[39m DecisionTreeClassifier(max_depth\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n\u001b[1;32m---> 13\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;66;03m# Ver importancia de las características y clases aprendidas\u001b[39;00m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mImportancia de características:\u001b[39m\u001b[38;5;124m\"\u001b[39m, model\u001b[38;5;241m.\u001b[39mfeature_importances_)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py:1473\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1466\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1468\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1469\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1470\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1471\u001b[0m     )\n\u001b[0;32m   1472\u001b[0m ):\n\u001b[1;32m-> 1473\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\tree\\_classes.py:1009\u001b[0m, in \u001b[0;36mDecisionTreeClassifier.fit\u001b[1;34m(self, X, y, sample_weight, check_input)\u001b[0m\n\u001b[0;32m    978\u001b[0m \u001b[38;5;129m@_fit_context\u001b[39m(prefer_skip_nested_validation\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m    979\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y, sample_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, check_input\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[0;32m    980\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Build a decision tree classifier from the training set (X, y).\u001b[39;00m\n\u001b[0;32m    981\u001b[0m \n\u001b[0;32m    982\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1006\u001b[0m \u001b[38;5;124;03m        Fitted estimator.\u001b[39;00m\n\u001b[0;32m   1007\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1009\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1010\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1011\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1012\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1013\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcheck_input\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcheck_input\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1014\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1015\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\tree\\_classes.py:294\u001b[0m, in \u001b[0;36mBaseDecisionTree._fit\u001b[1;34m(self, X, y, sample_weight, check_input, missing_values_in_feature_mask)\u001b[0m\n\u001b[0;32m    291\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_outputs_ \u001b[38;5;241m=\u001b[39m y\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m    293\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_classification:\n\u001b[1;32m--> 294\u001b[0m     \u001b[43mcheck_classification_targets\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    295\u001b[0m     y \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mcopy(y)\n\u001b[0;32m    297\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses_ \u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\multiclass.py:211\u001b[0m, in \u001b[0;36mcheck_classification_targets\u001b[1;34m(y)\u001b[0m\n\u001b[0;32m    199\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcheck_classification_targets\u001b[39m(y):\n\u001b[0;32m    200\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Ensure that target y is of a non-regression type.\u001b[39;00m\n\u001b[0;32m    201\u001b[0m \n\u001b[0;32m    202\u001b[0m \u001b[38;5;124;03m    Only the following target types (as defined in type_of_target) are allowed:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    209\u001b[0m \u001b[38;5;124;03m        Target values.\u001b[39;00m\n\u001b[0;32m    210\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 211\u001b[0m     y_type \u001b[38;5;241m=\u001b[39m \u001b[43mtype_of_target\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43my\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    212\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m y_type \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m [\n\u001b[0;32m    213\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbinary\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    214\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmulticlass\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    217\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmultilabel-sequences\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    218\u001b[0m     ]:\n\u001b[0;32m    219\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    220\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnknown label type: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00my_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. Maybe you are trying to fit a \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    221\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclassifier, which expects discrete classes on a \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    222\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mregression target with continuous values.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    223\u001b[0m         )\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\multiclass.py:404\u001b[0m, in \u001b[0;36mtype_of_target\u001b[1;34m(y, input_name)\u001b[0m\n\u001b[0;32m    402\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m issparse(first_row_or_val):\n\u001b[0;32m    403\u001b[0m     first_row_or_val \u001b[38;5;241m=\u001b[39m first_row_or_val\u001b[38;5;241m.\u001b[39mdata\n\u001b[1;32m--> 404\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mxp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munique_values\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m (y\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(first_row_or_val) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m):\n\u001b[0;32m    405\u001b[0m     \u001b[38;5;66;03m# [1, 2, 3] or [[1., 2., 3]] or [[1, 2]]\u001b[39;00m\n\u001b[0;32m    406\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmulticlass\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m suffix\n\u001b[0;32m    407\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\_array_api.py:407\u001b[0m, in \u001b[0;36m_NumPyAPIWrapper.unique_values\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    406\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21munique_values\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[1;32m--> 407\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mnumpy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munique\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\numpy\\lib\\arraysetops.py:274\u001b[0m, in \u001b[0;36munique\u001b[1;34m(ar, return_index, return_inverse, return_counts, axis, equal_nan)\u001b[0m\n\u001b[0;32m    272\u001b[0m ar \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masanyarray(ar)\n\u001b[0;32m    273\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m axis \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 274\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[43m_unique1d\u001b[49m\u001b[43m(\u001b[49m\u001b[43mar\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_inverse\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_counts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m    275\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mequal_nan\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mequal_nan\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    276\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _unpack_tuple(ret)\n\u001b[0;32m    278\u001b[0m \u001b[38;5;66;03m# axis was specified and not None\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\numpy\\lib\\arraysetops.py:336\u001b[0m, in \u001b[0;36m_unique1d\u001b[1;34m(ar, return_index, return_inverse, return_counts, equal_nan)\u001b[0m\n\u001b[0;32m    334\u001b[0m     aux \u001b[38;5;241m=\u001b[39m ar[perm]\n\u001b[0;32m    335\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 336\u001b[0m     \u001b[43mar\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msort\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    337\u001b[0m     aux \u001b[38;5;241m=\u001b[39m ar\n\u001b[0;32m    338\u001b[0m mask \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mempty(aux\u001b[38;5;241m.\u001b[39mshape, dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mbool_)\n",
      "\u001b[1;31mTypeError\u001b[0m: '<' not supported between instances of 'int' and 'str'"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Combinar los conjuntos de datos\n",
    "X = np.concatenate((X_complejo, X_dinamico), axis=0)\n",
    "y = np.concatenate((y_complejo, y_dinamico), axis=0)\n",
    "\n",
    "# Dividir los datos en entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Crear y entrenar el modelo\n",
    "model = DecisionTreeClassifier(max_depth=5, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Ver importancia de las características y clases aprendidas\n",
    "print(\"Importancia de características:\", model.feature_importances_)\n",
    "print(\"Clases aprendidas:\", model.classes_)\n",
    "\n",
    "# Realizar predicciones en los datos de prueba\n",
    "predicciones = model.predict(X_test)\n",
    "print(\"Predicciones en datos de prueba:\", predicciones)\n",
    "\n",
    "# Evaluar el modelo en los datos de prueba\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, predicciones))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "857154ba-c66a-4210-a6a5-23ea7393eb18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datos X (complejo): [[1 1 0]\n",
      " [2 1 1]\n",
      " [5 4 1]\n",
      " [2 1 1]\n",
      " [5 1 0]\n",
      " [3 4 1]\n",
      " [5 2 0]\n",
      " [2 4 0]\n",
      " [4 1 1]\n",
      " [4 1 1]\n",
      " [2 2 0]\n",
      " [5 1 0]\n",
      " [4 3 1]\n",
      " [3 3 1]\n",
      " [4 5 1]\n",
      " [2 3 0]\n",
      " [5 5 0]\n",
      " [4 4 1]\n",
      " [5 5 0]\n",
      " [5 5 0]\n",
      " [2 3 0]\n",
      " [5 1 1]\n",
      " [4 1 0]\n",
      " [1 2 1]\n",
      " [4 1 1]\n",
      " [3 2 0]\n",
      " [5 3 1]\n",
      " [4 3 1]\n",
      " [1 4 0]\n",
      " [5 1 1]\n",
      " [4 4 0]\n",
      " [1 2 1]\n",
      " [4 2 1]\n",
      " [2 4 0]\n",
      " [4 3 0]\n",
      " [5 2 0]\n",
      " [4 1 0]\n",
      " [5 3 1]\n",
      " [4 1 1]\n",
      " [1 4 0]\n",
      " [1 3 1]\n",
      " [2 3 0]\n",
      " [3 4 0]\n",
      " [1 3 0]\n",
      " [2 4 1]\n",
      " [5 2 0]\n",
      " [2 2 0]\n",
      " [5 5 1]\n",
      " [5 5 0]\n",
      " [4 3 0]\n",
      " [2 1 1]\n",
      " [3 1 0]\n",
      " [5 4 1]\n",
      " [4 2 0]\n",
      " [2 2 0]\n",
      " [4 1 0]\n",
      " [2 5 1]\n",
      " [3 2 0]\n",
      " [2 3 1]\n",
      " [1 5 1]\n",
      " [4 3 1]\n",
      " [5 3 0]\n",
      " [3 3 0]\n",
      " [5 2 1]\n",
      " [1 3 1]\n",
      " [3 5 1]\n",
      " [5 4 0]\n",
      " [2 2 0]\n",
      " [5 3 1]\n",
      " [2 2 1]\n",
      " [2 3 0]\n",
      " [4 3 1]\n",
      " [4 5 0]\n",
      " [4 5 0]\n",
      " [5 3 1]\n",
      " [1 5 1]\n",
      " [3 3 1]\n",
      " [1 4 0]\n",
      " [3 2 0]\n",
      " [1 3 1]\n",
      " [1 5 0]\n",
      " [5 5 0]\n",
      " [2 5 1]\n",
      " [2 4 0]\n",
      " [5 5 1]\n",
      " [3 4 0]\n",
      " [5 4 1]\n",
      " [4 2 0]\n",
      " [4 4 1]\n",
      " [2 1 0]\n",
      " [1 5 1]\n",
      " [2 5 0]\n",
      " [1 2 0]\n",
      " [5 4 0]\n",
      " [5 5 0]\n",
      " [1 4 1]\n",
      " [5 4 1]\n",
      " [1 3 0]\n",
      " [5 4 0]\n",
      " [1 3 0]\n",
      " [2 2 1]\n",
      " [4 1 0]\n",
      " [5 1 0]\n",
      " [5 1 1]\n",
      " [2 4 1]\n",
      " [2 4 0]\n",
      " [1 5 0]\n",
      " [5 1 0]\n",
      " [5 3 0]\n",
      " [1 1 1]\n",
      " [5 2 1]\n",
      " [5 4 0]\n",
      " [3 2 0]\n",
      " [5 1 1]\n",
      " [2 3 0]\n",
      " [1 3 0]\n",
      " [3 1 0]\n",
      " [2 5 0]\n",
      " [5 3 1]\n",
      " [1 1 0]\n",
      " [1 3 0]\n",
      " [4 2 0]\n",
      " [1 5 1]\n",
      " [4 2 0]\n",
      " [5 3 0]\n",
      " [3 1 0]\n",
      " [2 3 0]\n",
      " [5 1 1]\n",
      " [5 2 0]\n",
      " [5 3 1]\n",
      " [5 2 0]\n",
      " [4 1 0]\n",
      " [5 4 1]\n",
      " [2 1 0]\n",
      " [3 4 0]\n",
      " [2 1 1]\n",
      " [2 2 0]\n",
      " [4 1 1]\n",
      " [1 1 1]\n",
      " [3 5 0]\n",
      " [2 2 0]\n",
      " [2 1 1]\n",
      " [4 2 1]\n",
      " [4 3 0]\n",
      " [5 1 0]\n",
      " [1 2 0]\n",
      " [1 1 1]\n",
      " [4 4 0]\n",
      " [2 1 0]\n",
      " [2 1 1]\n",
      " [2 5 0]\n",
      " [4 1 1]\n",
      " [3 1 0]\n",
      " [1 5 0]\n",
      " [3 1 0]\n",
      " [3 5 0]\n",
      " [3 2 1]\n",
      " [4 5 1]\n",
      " [1 1 0]\n",
      " [3 1 0]\n",
      " [5 2 1]\n",
      " [4 5 1]\n",
      " [1 2 1]\n",
      " [5 1 0]\n",
      " [1 3 0]\n",
      " [2 5 1]\n",
      " [1 1 1]\n",
      " [5 1 1]\n",
      " [4 2 0]\n",
      " [1 1 1]\n",
      " [2 5 1]\n",
      " [4 5 1]\n",
      " [1 3 0]\n",
      " [2 3 1]\n",
      " [5 2 1]\n",
      " [3 5 0]\n",
      " [3 5 1]\n",
      " [2 5 1]\n",
      " [2 4 1]\n",
      " [3 1 1]\n",
      " [4 3 0]\n",
      " [5 5 1]\n",
      " [5 5 0]\n",
      " [4 2 0]\n",
      " [1 5 1]\n",
      " [5 2 0]\n",
      " [5 2 0]\n",
      " [5 2 1]\n",
      " [4 1 0]\n",
      " [5 5 1]\n",
      " [5 3 1]\n",
      " [2 5 0]\n",
      " [5 2 0]\n",
      " [2 3 1]\n",
      " [4 5 0]\n",
      " [5 2 1]\n",
      " [1 4 1]\n",
      " [2 3 1]\n",
      " [4 1 1]\n",
      " [5 2 1]]\n",
      "Datos y (complejo): [17 38 26 35 10  6 33 20 43 36  2 35  4  3 40  8 20  3 20 32 12 19 45 31\n",
      " 34 10 25  1 38  2 14  8 41  4 25 10  4 13 34  7  5 19  5 31 11 26 41 10\n",
      " 16 25  4  8 24  8 23 16 32 17 42 25 31 34 17 15 19 32 27  4 43 22 25 12\n",
      " 26 39 38 31 45 41 14 11 39 39 37 26 41 35 11 42 41  6 21  3 25 27 17 30\n",
      " 37 31 26 11 44 41 11 11  6 27 28 12  2 36 31  3 33  9 39 19 15 18 34 40\n",
      " 22 40 44 40 25 30 26  6  2 30  6 23 20 16  2  3 36 35  3 21 44 26 22 27\n",
      " 38 44 43 18  8 30 34  1 39 33 23 40 44 36 40 32 22 22 23 30 17 44 32 22\n",
      " 32 17 20 25 27 45  6 42 36 26 19 10 22 20 19 40 26  2 38  9  2 29 13 27\n",
      "  9 37  5  5  7 15 11 21]\n",
      "Datos X (dinámico): [[5 2 1]\n",
      " [4 2 0]\n",
      " [5 2 1]\n",
      " [4 1 0]\n",
      " [1 1 0]\n",
      " [5 4 1]\n",
      " [4 3 1]\n",
      " [3 3 1]\n",
      " [3 2 1]\n",
      " [1 5 0]\n",
      " [4 1 0]\n",
      " [3 4 1]\n",
      " [5 1 0]\n",
      " [2 3 0]\n",
      " [5 2 0]\n",
      " [2 5 0]\n",
      " [5 1 0]\n",
      " [5 1 0]\n",
      " [3 1 0]\n",
      " [1 5 1]\n",
      " [1 2 1]\n",
      " [5 4 0]\n",
      " [3 5 0]\n",
      " [3 3 1]\n",
      " [5 2 1]\n",
      " [2 2 1]\n",
      " [4 3 0]\n",
      " [4 1 0]\n",
      " [1 1 0]\n",
      " [4 2 0]\n",
      " [3 3 0]\n",
      " [4 2 0]\n",
      " [5 3 0]\n",
      " [3 1 0]\n",
      " [3 3 1]\n",
      " [5 1 0]\n",
      " [4 3 0]\n",
      " [2 1 0]\n",
      " [4 4 0]\n",
      " [4 4 1]\n",
      " [3 4 0]\n",
      " [1 1 1]\n",
      " [1 1 0]\n",
      " [4 4 1]\n",
      " [2 2 0]\n",
      " [4 3 1]\n",
      " [4 2 0]\n",
      " [1 1 0]\n",
      " [1 4 1]\n",
      " [5 3 0]\n",
      " [5 4 1]\n",
      " [3 4 0]\n",
      " [2 2 0]\n",
      " [3 5 0]\n",
      " [5 2 0]\n",
      " [4 4 1]\n",
      " [4 3 0]\n",
      " [3 4 1]\n",
      " [5 4 1]\n",
      " [2 4 1]\n",
      " [3 1 1]\n",
      " [4 2 1]\n",
      " [4 3 0]\n",
      " [5 1 0]\n",
      " [3 1 1]\n",
      " [5 2 1]\n",
      " [4 5 0]\n",
      " [4 2 0]\n",
      " [2 2 0]\n",
      " [3 5 1]\n",
      " [2 1 0]\n",
      " [5 3 0]\n",
      " [4 1 1]\n",
      " [5 3 0]\n",
      " [5 5 0]\n",
      " [4 1 0]\n",
      " [1 4 0]\n",
      " [5 5 0]\n",
      " [4 1 0]\n",
      " [4 4 0]\n",
      " [3 2 1]\n",
      " [4 5 0]\n",
      " [1 5 0]\n",
      " [5 1 0]\n",
      " [4 4 1]\n",
      " [5 4 1]\n",
      " [5 1 0]\n",
      " [1 5 1]\n",
      " [5 5 0]\n",
      " [4 4 0]\n",
      " [2 4 0]\n",
      " [2 2 1]\n",
      " [2 2 0]\n",
      " [5 4 0]\n",
      " [2 3 0]\n",
      " [2 4 1]\n",
      " [3 4 1]\n",
      " [4 1 1]\n",
      " [1 3 1]\n",
      " [1 5 1]]\n",
      "Datos y (dinámico): [0 0 0 0 0 2 1 1 0 0 0 1 0 0 0 0 0 0 0 0 0 2 1 1 0 0 1 0 0 0 1 0 1 0 1 0 1\n",
      " 0 2 2 1 0 0 2 0 1 0 0 0 1 2 1 0 1 0 2 1 1 2 0 0 0 1 0 0 0 2 0 0 1 0 1 0 1\n",
      " 2 0 0 2 0 2 0 2 0 0 2 2 0 0 2 2 0 0 0 2 0 0 1 0 0 0]\n",
      "Datos y después de la conversión a enteros: [17 38 26 35 10  6 33 20 43 36  2 35  4  3 40  8 20  3 20 32 12 19 45 31\n",
      " 34 10 25  1 38  2 14  8 41  4 25 10  4 13 34  7  5 19  5 31 11 26 41 10\n",
      " 16 25  4  8 24  8 23 16 32 17 42 25 31 34 17 15 19 32 27  4 43 22 25 12\n",
      " 26 39 38 31 45 41 14 11 39 39 37 26 41 35 11 42 41  6 21  3 25 27 17 30\n",
      " 37 31 26 11 44 41 11 11  6 27 28 12  2 36 31  3 33  9 39 19 15 18 34 40\n",
      " 22 40 44 40 25 30 26  6  2 30  6 23 20 16  2  3 36 35  3 21 44 26 22 27\n",
      " 38 44 43 18  8 30 34  1 39 33 23 40 44 36 40 32 22 22 23 30 17 44 32 22\n",
      " 32 17 20 25 27 45  6 42 36 26 19 10 22 20 19 40 26  2 38  9  2 29 13 27\n",
      "  9 37  5  5  7 15 11 21  0  0  0  0  0  2  1  1  0  0  0  1  0  0  0  0\n",
      "  0  0  0  0  0  2  1  1  0  0  1  0  0  0  1  0  1  0  1  0  1  0  2  2\n",
      "  1  0  0  2  0  1  0  0  0  1  2  1  0  1  0  2  1  1  2  0  0  0  1  0\n",
      "  0  0  2  0  0  1  0  1  0  1  2  0  0  2  0  2  0  2  0  0  2  2  0  0\n",
      "  2  2  0  0  0  2  0  0  1  0  0  0]\n",
      "Importancia de características: [0.45943938 0.42992638 0.11063424]\n",
      "Clases aprendidas: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45]\n",
      "Predicción para datos de prueba: [0]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Cargar el CSV\n",
    "df_complejo = pd.read_csv(\"conjunto_datos_tareas_complejo.csv\")\n",
    "df_dinamico = pd.read_csv(\"conjunto_datos_tareas_dinamico.csv\")\n",
    "\n",
    "# Seleccionar las características y la etiqueta\n",
    "X_complejo = df_complejo[['urgencia', 'importancia', 'prioridad_externa']].values\n",
    "y_complejo = df_complejo['dias_restantes'].values\n",
    "\n",
    "X_dinamico = df_dinamico[['urgencia', 'importancia', 'prioridad_externa']].values\n",
    "# Mapear clasificaciones categóricas a valores numéricos\n",
    "y_dinamico = df_dinamico['clasificacion'].map({'Baja prioridad': 0, 'Media prioridad': 1, 'Alta prioridad': 2}).values\n",
    "\n",
    "# Imprimir los datos para revisar\n",
    "print(\"Datos X (complejo):\", X_complejo)\n",
    "print(\"Datos y (complejo):\", y_complejo)\n",
    "print(\"Datos X (dinámico):\", X_dinamico)\n",
    "print(\"Datos y (dinámico):\", y_dinamico)\n",
    "\n",
    "# Combinar ambos conjuntos de datos\n",
    "X = np.concatenate((X_complejo, X_dinamico), axis=0)\n",
    "y = np.concatenate((y_complejo, y_dinamico), axis=0)\n",
    "\n",
    "# Convertir y a enteros (si es necesario)\n",
    "y = y.astype(int)\n",
    "print(\"Datos y después de la conversión a enteros:\", y)\n",
    "\n",
    "# Dividir los datos en entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Crear y entrenar el modelo\n",
    "model = DecisionTreeClassifier(max_depth=5, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Ver importancia de las características y clases aprendidas\n",
    "print(\"Importancia de características:\", model.feature_importances_)\n",
    "print(\"Clases aprendidas:\", model.classes_)\n",
    "\n",
    "# Ejemplo de predicción con datos de prueba\n",
    "test_data = [[1, 2, 3]]  # Ajusta estos valores según tus datos\n",
    "prediccion = model.predict(test_data)\n",
    "print(\"Predicción para datos de prueba:\", prediccion)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "373a68a2-a8fd-41c4-a970-1099f1086b72",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'imblearn'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mimblearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mover_sampling\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m RandomOverSampler\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_selection\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m train_test_split\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m classification_report, confusion_matrix\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'imblearn'"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# Aplica sobremuestreo a los datos\n",
    "ros = RandomOverSampler(random_state=42)\n",
    "X_balanced, y_balanced = ros.fit_resample(X_complejo, y_complejo)\n",
    "\n",
    "# Divide los datos balanceados en entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_balanced, y_balanced, test_size=0.2, random_state=42)\n",
    "\n",
    "# Entrena el modelo nuevamente\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predice con los datos de prueba\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Muestra el reporte de clasificación y la matriz de confusión\n",
    "print(\"Reporte de Clasificación después del balanceo:\\n\", classification_report(y_test, y_pred))\n",
    "print(\"Matriz de Confusión después del balanceo:\\n\", confusion_matrix(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fde1ac5f-04fb-47fc-85f7-316bf8a0566a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting imbalanced-learn\n",
      "  Downloading imbalanced_learn-0.12.4-py3-none-any.whl.metadata (8.3 kB)\n",
      "Requirement already satisfied: numpy>=1.17.3 in c:\\users\\famag\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from imbalanced-learn) (1.26.4)\n",
      "Requirement already satisfied: scipy>=1.5.0 in c:\\users\\famag\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from imbalanced-learn) (1.14.1)\n",
      "Requirement already satisfied: scikit-learn>=1.0.2 in c:\\users\\famag\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from imbalanced-learn) (1.5.2)\n",
      "Requirement already satisfied: joblib>=1.1.1 in c:\\users\\famag\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from imbalanced-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\famag\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from imbalanced-learn) (3.5.0)\n",
      "Downloading imbalanced_learn-0.12.4-py3-none-any.whl (258 kB)\n",
      "Installing collected packages: imbalanced-learn\n",
      "Successfully installed imbalanced-learn-0.12.4\n"
     ]
    }
   ],
   "source": [
    "!pip install imbalanced-learn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e367baeb-064a-4978-8b1e-e529b8f7c6bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reporte de Clasificación después del balanceo:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         0\n",
      "           2       0.00      0.00      0.00         0\n",
      "           3       0.11      1.00      0.20         1\n",
      "           4       0.00      0.00      0.00         1\n",
      "           5       0.00      0.00      0.00         3\n",
      "           6       0.00      0.00      0.00         2\n",
      "           7       0.17      1.00      0.29         1\n",
      "           8       0.00      0.00      0.00         3\n",
      "           9       0.67      1.00      0.80         2\n",
      "          10       0.00      0.00      0.00         1\n",
      "          12       0.00      0.00      0.00         2\n",
      "          13       1.00      1.00      1.00         2\n",
      "          14       0.17      0.50      0.25         4\n",
      "          15       0.00      0.00      0.00         1\n",
      "          16       0.14      1.00      0.25         1\n",
      "          17       0.00      0.00      0.00         3\n",
      "          18       0.20      1.00      0.33         1\n",
      "          19       0.00      0.00      0.00         0\n",
      "          20       0.00      0.00      0.00         1\n",
      "          21       1.00      0.50      0.67         2\n",
      "          22       0.00      0.00      0.00         1\n",
      "          23       0.00      0.00      0.00         1\n",
      "          24       0.50      1.00      0.67         1\n",
      "          25       0.00      0.00      0.00         2\n",
      "          26       0.00      0.00      0.00         5\n",
      "          27       0.00      0.00      0.00         2\n",
      "          28       0.50      1.00      0.67         2\n",
      "          29       0.67      1.00      0.80         2\n",
      "          30       0.00      0.00      0.00         2\n",
      "          31       0.00      0.00      0.00         1\n",
      "          32       0.00      0.00      0.00         2\n",
      "          33       0.00      0.00      0.00         2\n",
      "          34       0.25      1.00      0.40         1\n",
      "          35       0.00      0.00      0.00         1\n",
      "          36       0.00      0.00      0.00         2\n",
      "          37       0.00      0.00      0.00         3\n",
      "          38       0.00      0.00      0.00         1\n",
      "          39       0.00      0.00      0.00         2\n",
      "          40       0.00      0.00      0.00         1\n",
      "          41       0.00      0.00      0.00         5\n",
      "          42       0.00      0.00      0.00         2\n",
      "          43       0.00      0.00      0.00         1\n",
      "          44       0.00      0.00      0.00         2\n",
      "          45       0.00      0.00      0.00         6\n",
      "\n",
      "    accuracy                           0.21        81\n",
      "   macro avg       0.12      0.25      0.14        81\n",
      "weighted avg       0.12      0.21      0.14        81\n",
      "\n",
      "Matriz de Confusión después del balanceo:\n",
      " [[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 1 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\famag\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\famag\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\famag\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\famag\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\famag\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\famag\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# Aplica sobremuestreo a los datos\n",
    "ros = RandomOverSampler(random_state=42)\n",
    "X_balanced, y_balanced = ros.fit_resample(X_complejo, y_complejo)\n",
    "\n",
    "# Divide los datos balanceados en entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_balanced, y_balanced, test_size=0.2, random_state=42)\n",
    "\n",
    "# Entrena el modelo nuevamente\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predice con los datos de prueba\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Muestra el reporte de clasificación y la matriz de confusión\n",
    "print(\"Reporte de Clasificación después del balanceo:\\n\", classification_report(y_test, y_pred))\n",
    "print(\"Matriz de Confusión después del balanceo:\\n\", confusion_matrix(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b27296ad-705a-4864-be33-eafb3a504453",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reporte de Clasificación después del balanceo:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         0\n",
      "           2       0.00      0.00      0.00         0\n",
      "           3       0.00      0.00      0.00         1\n",
      "           4       0.00      0.00      0.00         1\n",
      "           5       0.00      0.00      0.00         3\n",
      "           6       0.00      0.00      0.00         2\n",
      "           7       0.17      1.00      0.29         1\n",
      "           8       0.17      0.33      0.22         3\n",
      "           9       0.67      1.00      0.80         2\n",
      "          10       0.00      0.00      0.00         1\n",
      "          11       0.00      0.00      0.00         0\n",
      "          12       0.00      0.00      0.00         2\n",
      "          13       1.00      1.00      1.00         2\n",
      "          14       0.50      0.50      0.50         4\n",
      "          15       0.00      0.00      0.00         1\n",
      "          16       0.20      1.00      0.33         1\n",
      "          17       0.00      0.00      0.00         3\n",
      "          18       0.33      1.00      0.50         1\n",
      "          19       0.00      0.00      0.00         0\n",
      "          20       0.00      0.00      0.00         1\n",
      "          21       0.50      1.00      0.67         2\n",
      "          22       0.00      0.00      0.00         1\n",
      "          23       0.20      1.00      0.33         1\n",
      "          24       0.50      1.00      0.67         1\n",
      "          25       0.00      0.00      0.00         2\n",
      "          26       0.00      0.00      0.00         5\n",
      "          27       0.00      0.00      0.00         2\n",
      "          28       0.50      1.00      0.67         2\n",
      "          29       0.67      1.00      0.80         2\n",
      "          30       0.00      0.00      0.00         2\n",
      "          31       0.00      0.00      0.00         1\n",
      "          32       0.00      0.00      0.00         2\n",
      "          33       0.00      0.00      0.00         2\n",
      "          34       0.25      1.00      0.40         1\n",
      "          35       0.00      0.00      0.00         1\n",
      "          36       0.00      0.00      0.00         2\n",
      "          37       0.00      0.00      0.00         3\n",
      "          38       0.00      0.00      0.00         1\n",
      "          39       0.50      0.50      0.50         2\n",
      "          40       0.00      0.00      0.00         1\n",
      "          41       0.00      0.00      0.00         5\n",
      "          42       0.00      0.00      0.00         2\n",
      "          43       0.00      0.00      0.00         1\n",
      "          44       0.20      0.50      0.29         2\n",
      "          45       1.00      0.33      0.50         6\n",
      "\n",
      "    accuracy                           0.28        81\n",
      "   macro avg       0.16      0.29      0.19        81\n",
      "weighted avg       0.22      0.28      0.22        81\n",
      "\n",
      "Matriz de Confusión después del balanceo:\n",
      " [[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 1 0]\n",
      " [0 0 0 ... 0 0 2]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\famag\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\famag\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\famag\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\famag\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\famag\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\famag\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "\n",
    "# Aplica sobremuestreo a los datos\n",
    "ros = RandomOverSampler(random_state=42)\n",
    "X_balanced, y_balanced = ros.fit_resample(X_complejo, y_complejo)\n",
    "\n",
    "# Divide los datos balanceados en entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_balanced, y_balanced, test_size=0.2, random_state=42)\n",
    "\n",
    "# Crear y entrenar un modelo de bosque aleatorio\n",
    "model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predice con los datos de prueba\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Muestra el reporte de clasificación y la matriz de confusión\n",
    "print(\"Reporte de Clasificación después del balanceo:\\n\", classification_report(y_test, y_pred))\n",
    "print(\"Matriz de Confusión después del balanceo:\\n\", confusion_matrix(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ba8c38b1-a704-42a5-9a59-9c8b984e98f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 216 candidates, totalling 648 fits\n",
      "Mejores parámetros encontrados: {'class_weight': 'balanced', 'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 5, 'n_estimators': 50}\n",
      "Reporte de Clasificación después del ajuste de hiperparámetros:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         0\n",
      "           2       0.00      0.00      0.00         0\n",
      "           3       0.00      0.00      0.00         1\n",
      "           4       0.00      0.00      0.00         1\n",
      "           5       0.00      0.00      0.00         3\n",
      "           6       0.00      0.00      0.00         2\n",
      "           7       0.17      1.00      0.29         1\n",
      "           8       0.17      0.33      0.22         3\n",
      "           9       0.67      1.00      0.80         2\n",
      "          10       0.00      0.00      0.00         1\n",
      "          12       0.00      0.00      0.00         2\n",
      "          13       1.00      1.00      1.00         2\n",
      "          14       0.50      0.50      0.50         4\n",
      "          15       0.00      0.00      0.00         1\n",
      "          16       0.20      1.00      0.33         1\n",
      "          17       0.00      0.00      0.00         3\n",
      "          18       0.33      1.00      0.50         1\n",
      "          19       0.00      0.00      0.00         0\n",
      "          20       0.00      0.00      0.00         1\n",
      "          21       1.00      0.50      0.67         2\n",
      "          22       0.00      0.00      0.00         1\n",
      "          23       0.20      1.00      0.33         1\n",
      "          24       0.50      1.00      0.67         1\n",
      "          25       0.00      0.00      0.00         2\n",
      "          26       0.00      0.00      0.00         5\n",
      "          27       0.00      0.00      0.00         2\n",
      "          28       0.50      1.00      0.67         2\n",
      "          29       0.67      1.00      0.80         2\n",
      "          30       0.00      0.00      0.00         2\n",
      "          31       0.00      0.00      0.00         1\n",
      "          32       0.00      0.00      0.00         2\n",
      "          33       0.00      0.00      0.00         2\n",
      "          34       0.25      1.00      0.40         1\n",
      "          35       0.00      0.00      0.00         1\n",
      "          36       0.00      0.00      0.00         2\n",
      "          37       0.00      0.00      0.00         3\n",
      "          38       0.00      0.00      0.00         1\n",
      "          39       0.00      0.00      0.00         2\n",
      "          40       0.00      0.00      0.00         1\n",
      "          41       0.00      0.00      0.00         5\n",
      "          42       0.20      0.50      0.29         2\n",
      "          43       0.00      0.00      0.00         1\n",
      "          44       0.20      0.50      0.29         2\n",
      "          45       1.00      0.33      0.50         6\n",
      "\n",
      "    accuracy                           0.27        81\n",
      "   macro avg       0.17      0.29      0.19        81\n",
      "weighted avg       0.23      0.27      0.21        81\n",
      "\n",
      "Matriz de Confusión después del ajuste de hiperparámetros:\n",
      " [[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 1 0]\n",
      " [0 0 0 ... 0 0 2]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\famag\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\famag\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\famag\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\famag\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\famag\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\famag\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "\n",
    "# Balanceo de clases con RandomOverSampler\n",
    "ros = RandomOverSampler(random_state=42)\n",
    "X_balanced, y_balanced = ros.fit_resample(X_complejo, y_complejo)\n",
    "\n",
    "# Parámetros para búsqueda en cuadrícula\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 200],  # Número de árboles en el bosque\n",
    "    'max_depth': [None, 10, 20, 30],  # Profundidad máxima de cada árbol\n",
    "    'min_samples_split': [2, 5, 10],  # Número mínimo de muestras necesarias para dividir un nodo\n",
    "    'min_samples_leaf': [1, 2, 4],    # Número mínimo de muestras en una hoja\n",
    "    'class_weight': [None, 'balanced']  # Ponderación de clases\n",
    "}\n",
    "\n",
    "# Configuración del clasificador RandomForest con búsqueda de cuadrícula\n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "grid_search = GridSearchCV(estimator=rf, param_grid=param_grid, cv=3, n_jobs=-1, verbose=2, scoring='f1_weighted')\n",
    "\n",
    "# División de los datos\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_balanced, y_balanced, test_size=0.2, random_state=42)\n",
    "\n",
    "# Entrenamiento con la búsqueda de cuadrícula\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Mejor modelo obtenido\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "# Predicción con los datos de prueba\n",
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "# Resultados\n",
    "print(\"Mejores parámetros encontrados:\", grid_search.best_params_)\n",
    "print(\"Reporte de Clasificación después del ajuste de hiperparámetros:\\n\", classification_report(y_test, y_pred))\n",
    "print(\"Matriz de Confusión después del ajuste de hiperparámetros:\\n\", confusion_matrix(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "50d4717a-1078-46ea-92f1-2f3aa8a4236a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting imblearn\n",
      "  Downloading imblearn-0.0-py2.py3-none-any.whl.metadata (355 bytes)\n",
      "Requirement already satisfied: imbalanced-learn in c:\\users\\famag\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from imblearn) (0.12.4)\n",
      "Requirement already satisfied: numpy>=1.17.3 in c:\\users\\famag\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from imbalanced-learn->imblearn) (1.26.4)\n",
      "Requirement already satisfied: scipy>=1.5.0 in c:\\users\\famag\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from imbalanced-learn->imblearn) (1.14.1)\n",
      "Requirement already satisfied: scikit-learn>=1.0.2 in c:\\users\\famag\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from imbalanced-learn->imblearn) (1.5.2)\n",
      "Requirement already satisfied: joblib>=1.1.1 in c:\\users\\famag\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from imbalanced-learn->imblearn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\famag\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from imbalanced-learn->imblearn) (3.5.0)\n",
      "Downloading imblearn-0.0-py2.py3-none-any.whl (1.9 kB)\n",
      "Installing collected packages: imblearn\n",
      "Successfully installed imblearn-0.0\n"
     ]
    }
   ],
   "source": [
    "!pip install imblearn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "48b125c1-2df9-43b2-905f-f045d38219e1",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Expected n_neighbors <= n_samples_fit, but n_neighbors = 6, n_samples_fit = 2, n_samples = 2",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[20], line 17\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# Configuración de datos para esta prueba\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# Estos deben reemplazarse por los datos X_complejo e y_complejo\u001b[39;00m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# que deben estar definidos en el entorno para ejecutar esta prueba\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     14\u001b[0m \n\u001b[0;32m     15\u001b[0m \u001b[38;5;66;03m# Aplica SMOTE para balanceo de clases\u001b[39;00m\n\u001b[0;32m     16\u001b[0m smote \u001b[38;5;241m=\u001b[39m SMOTE(random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n\u001b[1;32m---> 17\u001b[0m X_balanced, y_balanced \u001b[38;5;241m=\u001b[39m \u001b[43msmote\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_resample\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_complejo\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_complejo\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;66;03m# Define un conjunto de hiperparámetros reducido para optimizar tiempo de prueba\u001b[39;00m\n\u001b[0;32m     20\u001b[0m param_grid \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m     21\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mn_estimators\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;241m50\u001b[39m, \u001b[38;5;241m100\u001b[39m],  \u001b[38;5;66;03m# Ajuste rápido de n_estimadores\u001b[39;00m\n\u001b[0;32m     22\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmax_depth\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m10\u001b[39m, \u001b[38;5;241m20\u001b[39m],  \u001b[38;5;66;03m# Control de profundidad para evitar sobreajuste\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     25\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mclass_weight\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbalanced\u001b[39m\u001b[38;5;124m'\u001b[39m]   \u001b[38;5;66;03m# Ajuste de ponderación automática\u001b[39;00m\n\u001b[0;32m     26\u001b[0m }\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\imblearn\\base.py:208\u001b[0m, in \u001b[0;36mBaseSampler.fit_resample\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    187\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Resample the dataset.\u001b[39;00m\n\u001b[0;32m    188\u001b[0m \n\u001b[0;32m    189\u001b[0m \u001b[38;5;124;03mParameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    205\u001b[0m \u001b[38;5;124;03m    The corresponding label of `X_resampled`.\u001b[39;00m\n\u001b[0;32m    206\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    207\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m--> 208\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_resample\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\imblearn\\base.py:112\u001b[0m, in \u001b[0;36mSamplerMixin.fit_resample\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    106\u001b[0m X, y, binarize_y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_X_y(X, y)\n\u001b[0;32m    108\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msampling_strategy_ \u001b[38;5;241m=\u001b[39m check_sampling_strategy(\n\u001b[0;32m    109\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msampling_strategy, y, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampling_type\n\u001b[0;32m    110\u001b[0m )\n\u001b[1;32m--> 112\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit_resample\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    114\u001b[0m y_ \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    115\u001b[0m     label_binarize(output[\u001b[38;5;241m1\u001b[39m], classes\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39munique(y)) \u001b[38;5;28;01mif\u001b[39;00m binarize_y \u001b[38;5;28;01melse\u001b[39;00m output[\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m    116\u001b[0m )\n\u001b[0;32m    118\u001b[0m X_, y_ \u001b[38;5;241m=\u001b[39m arrays_transformer\u001b[38;5;241m.\u001b[39mtransform(output[\u001b[38;5;241m0\u001b[39m], y_)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\imblearn\\over_sampling\\_smote\\base.py:389\u001b[0m, in \u001b[0;36mSMOTE._fit_resample\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    386\u001b[0m X_class \u001b[38;5;241m=\u001b[39m _safe_indexing(X, target_class_indices)\n\u001b[0;32m    388\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnn_k_\u001b[38;5;241m.\u001b[39mfit(X_class)\n\u001b[1;32m--> 389\u001b[0m nns \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnn_k_\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkneighbors\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_class\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_distance\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m[:, \u001b[38;5;241m1\u001b[39m:]\n\u001b[0;32m    390\u001b[0m X_new, y_new \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_samples(\n\u001b[0;32m    391\u001b[0m     X_class, y\u001b[38;5;241m.\u001b[39mdtype, class_sample, X_class, nns, n_samples, \u001b[38;5;241m1.0\u001b[39m\n\u001b[0;32m    392\u001b[0m )\n\u001b[0;32m    393\u001b[0m X_resampled\u001b[38;5;241m.\u001b[39mappend(X_new)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:834\u001b[0m, in \u001b[0;36mKNeighborsMixin.kneighbors\u001b[1;34m(self, X, n_neighbors, return_distance)\u001b[0m\n\u001b[0;32m    832\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    833\u001b[0m         inequality_str \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mn_neighbors <= n_samples_fit\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m--> 834\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    835\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected \u001b[39m\u001b[38;5;132;01m{\u001b[39;00minequality_str\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, but \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    836\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mn_neighbors = \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mn_neighbors\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, n_samples_fit = \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mn_samples_fit\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    837\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mn_samples = \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mX\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m  \u001b[38;5;66;03m# include n_samples for common tests\u001b[39;00m\n\u001b[0;32m    838\u001b[0m     )\n\u001b[0;32m    840\u001b[0m n_jobs \u001b[38;5;241m=\u001b[39m effective_n_jobs(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_jobs)\n\u001b[0;32m    841\u001b[0m chunked_results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: Expected n_neighbors <= n_samples_fit, but n_neighbors = 6, n_samples_fit = 2, n_samples = 2"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# Configuración de datos para esta prueba\n",
    "# Estos deben reemplazarse por los datos X_complejo e y_complejo\n",
    "# que deben estar definidos en el entorno para ejecutar esta prueba\n",
    "\n",
    "# Datos simulados de ejemplo (para esta prueba)\n",
    "# Utilizar en el entorno de pruebas reales\n",
    "# X_complejo = ...\n",
    "# y_complejo = ...\n",
    "\n",
    "# Aplica SMOTE para balanceo de clases\n",
    "smote = SMOTE(random_state=42)\n",
    "X_balanced, y_balanced = smote.fit_resample(X_complejo, y_complejo)\n",
    "\n",
    "# Define un conjunto de hiperparámetros reducido para optimizar tiempo de prueba\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100],  # Ajuste rápido de n_estimadores\n",
    "    'max_depth': [None, 10, 20],  # Control de profundidad para evitar sobreajuste\n",
    "    'min_samples_split': [5, 10],  # Reducir el número mínimo de muestras para dividir\n",
    "    'min_samples_leaf': [1, 2],    # Reducir el número mínimo de muestras en una hoja\n",
    "    'class_weight': ['balanced']   # Ajuste de ponderación automática\n",
    "}\n",
    "\n",
    "# Configura el clasificador con GridSearchCV\n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "grid_search = GridSearchCV(estimator=rf, param_grid=param_grid, cv=3, n_jobs=-1, verbose=2, scoring='f1_weighted')\n",
    "\n",
    "# Divide los datos balanceados\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_balanced, y_balanced, test_size=0.2, random_state=42)\n",
    "\n",
    "# Realiza el ajuste de hiperparámetros y entrenamiento del modelo\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Selecciona el mejor modelo\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "# Realiza predicciones con los datos de prueba\n",
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "# Muestra resultados\n",
    "mejores_parametros = grid_search.best_params_\n",
    "reporte_clasificacion = classification_report(y_test, y_pred)\n",
    "matriz_confusion = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "(mejores_parametros, reporte_clasificacion, matriz_confusion)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "295be549-5a50-44ca-94f4-5752a5b8a907",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 24 candidates, totalling 72 fits\n",
      "Mejores parámetros encontrados: {'class_weight': 'balanced', 'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 5, 'n_estimators': 50}\n",
      "Reporte de Clasificación después del ajuste de hiperparámetros:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         0\n",
      "           2       0.00      0.00      0.00         0\n",
      "           3       0.00      0.00      0.00         1\n",
      "           4       0.00      0.00      0.00         1\n",
      "           5       0.00      0.00      0.00         3\n",
      "           6       0.00      0.00      0.00         2\n",
      "           7       0.17      1.00      0.29         1\n",
      "           8       0.17      0.33      0.22         3\n",
      "           9       0.67      1.00      0.80         2\n",
      "          10       0.00      0.00      0.00         1\n",
      "          12       0.00      0.00      0.00         2\n",
      "          13       1.00      1.00      1.00         2\n",
      "          14       0.50      0.50      0.50         4\n",
      "          15       0.00      0.00      0.00         1\n",
      "          16       0.20      1.00      0.33         1\n",
      "          17       0.00      0.00      0.00         3\n",
      "          18       0.33      1.00      0.50         1\n",
      "          19       0.00      0.00      0.00         0\n",
      "          20       0.00      0.00      0.00         1\n",
      "          21       1.00      0.50      0.67         2\n",
      "          22       0.00      0.00      0.00         1\n",
      "          23       0.20      1.00      0.33         1\n",
      "          24       0.50      1.00      0.67         1\n",
      "          25       0.00      0.00      0.00         2\n",
      "          26       0.00      0.00      0.00         5\n",
      "          27       0.00      0.00      0.00         2\n",
      "          28       0.50      1.00      0.67         2\n",
      "          29       0.67      1.00      0.80         2\n",
      "          30       0.00      0.00      0.00         2\n",
      "          31       0.00      0.00      0.00         1\n",
      "          32       0.00      0.00      0.00         2\n",
      "          33       0.00      0.00      0.00         2\n",
      "          34       0.25      1.00      0.40         1\n",
      "          35       0.00      0.00      0.00         1\n",
      "          36       0.00      0.00      0.00         2\n",
      "          37       0.00      0.00      0.00         3\n",
      "          38       0.00      0.00      0.00         1\n",
      "          39       0.00      0.00      0.00         2\n",
      "          40       0.00      0.00      0.00         1\n",
      "          41       0.00      0.00      0.00         5\n",
      "          42       0.20      0.50      0.29         2\n",
      "          43       0.00      0.00      0.00         1\n",
      "          44       0.20      0.50      0.29         2\n",
      "          45       1.00      0.33      0.50         6\n",
      "\n",
      "    accuracy                           0.27        81\n",
      "   macro avg       0.17      0.29      0.19        81\n",
      "weighted avg       0.23      0.27      0.21        81\n",
      "\n",
      "Matriz de Confusión después del ajuste de hiperparámetros:\n",
      " [[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 1 0]\n",
      " [0 0 0 ... 0 0 2]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\famag\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\famag\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\famag\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\famag\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\famag\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\famag\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "\n",
    "# Aplica RandomOverSampler para balanceo de clases\n",
    "ros = RandomOverSampler(random_state=42)\n",
    "X_balanced, y_balanced = ros.fit_resample(X_complejo, y_complejo)\n",
    "\n",
    "# Define una cuadrícula de hiperparámetros para la búsqueda en cuadrícula\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100],            # Número de árboles en el bosque\n",
    "    'max_depth': [None, 10, 20],          # Profundidad máxima de cada árbol\n",
    "    'min_samples_split': [2, 5],          # Número mínimo de muestras necesarias para dividir un nodo\n",
    "    'min_samples_leaf': [1, 2],           # Número mínimo de muestras en una hoja\n",
    "    'class_weight': ['balanced']          # Ponderación de clases para balanceo automático\n",
    "}\n",
    "\n",
    "# Configuración del clasificador RandomForest con búsqueda de cuadrícula\n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "grid_search = GridSearchCV(estimator=rf, param_grid=param_grid, cv=3, n_jobs=-1, verbose=2, scoring='f1_weighted')\n",
    "\n",
    "# División de los datos balanceados en entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_balanced, y_balanced, test_size=0.2, random_state=42)\n",
    "\n",
    "# Entrenamiento con la búsqueda de cuadrícula\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Mejor modelo obtenido\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "# Predicción con los datos de prueba\n",
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "# Resultados\n",
    "print(\"Mejores parámetros encontrados:\", grid_search.best_params_)\n",
    "print(\"Reporte de Clasificación después del ajuste de hiperparámetros:\\n\", classification_report(y_test, y_pred))\n",
    "print(\"Matriz de Confusión después del ajuste de hiperparámetros:\\n\", confusion_matrix(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e42f9cd0-0942-4ed4-8db3-220f317ce1ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 24 candidates, totalling 72 fits\n",
      "Mejores parámetros encontrados: {'class_weight': 'balanced', 'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 5, 'n_estimators': 50}\n",
      "Reporte de Clasificación:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         0\n",
      "           2       0.00      0.00      0.00         0\n",
      "           3       0.00      0.00      0.00         1\n",
      "           4       0.00      0.00      0.00         1\n",
      "           5       0.00      0.00      0.00         3\n",
      "           6       0.00      0.00      0.00         2\n",
      "           7       0.17      1.00      0.29         1\n",
      "           8       0.17      0.33      0.22         3\n",
      "           9       0.67      1.00      0.80         2\n",
      "          10       0.00      0.00      0.00         1\n",
      "          12       0.00      0.00      0.00         2\n",
      "          13       1.00      1.00      1.00         2\n",
      "          14       0.50      0.50      0.50         4\n",
      "          15       0.00      0.00      0.00         1\n",
      "          16       0.20      1.00      0.33         1\n",
      "          17       0.00      0.00      0.00         3\n",
      "          18       0.33      1.00      0.50         1\n",
      "          19       0.00      0.00      0.00         0\n",
      "          20       0.00      0.00      0.00         1\n",
      "          21       1.00      0.50      0.67         2\n",
      "          22       0.00      0.00      0.00         1\n",
      "          23       0.20      1.00      0.33         1\n",
      "          24       0.50      1.00      0.67         1\n",
      "          25       0.00      0.00      0.00         2\n",
      "          26       0.00      0.00      0.00         5\n",
      "          27       0.00      0.00      0.00         2\n",
      "          28       0.50      1.00      0.67         2\n",
      "          29       0.67      1.00      0.80         2\n",
      "          30       0.00      0.00      0.00         2\n",
      "          31       0.00      0.00      0.00         1\n",
      "          32       0.00      0.00      0.00         2\n",
      "          33       0.00      0.00      0.00         2\n",
      "          34       0.25      1.00      0.40         1\n",
      "          35       0.00      0.00      0.00         1\n",
      "          36       0.00      0.00      0.00         2\n",
      "          37       0.00      0.00      0.00         3\n",
      "          38       0.00      0.00      0.00         1\n",
      "          39       0.00      0.00      0.00         2\n",
      "          40       0.00      0.00      0.00         1\n",
      "          41       0.00      0.00      0.00         5\n",
      "          42       0.20      0.50      0.29         2\n",
      "          43       0.00      0.00      0.00         1\n",
      "          44       0.20      0.50      0.29         2\n",
      "          45       1.00      0.33      0.50         6\n",
      "\n",
      "    accuracy                           0.27        81\n",
      "   macro avg       0.17      0.29      0.19        81\n",
      "weighted avg       0.23      0.27      0.21        81\n",
      "\n",
      "Matriz de Confusión:\n",
      " [[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 1 0]\n",
      " [0 0 0 ... 0 0 2]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\famag\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\famag\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\famag\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\famag\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\famag\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\famag\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "\n",
    "# Paso 1: Balanceo de clases con RandomOverSampler\n",
    "ros = RandomOverSampler(random_state=42)\n",
    "X_balanced, y_balanced = ros.fit_resample(X_complejo, y_complejo)\n",
    "\n",
    "# Paso 2: Definición de los parámetros de la búsqueda en cuadrícula\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100],  # Ajustes rápidos de n_estimadores\n",
    "    'max_depth': [None, 10, 20],  # Control de profundidad\n",
    "    'min_samples_split': [2, 5],  # Evitar nodos muy pequeños\n",
    "    'min_samples_leaf': [1, 2],\n",
    "    'class_weight': ['balanced']\n",
    "}\n",
    "\n",
    "# Paso 3: Configuración del clasificador RandomForest\n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "grid_search = GridSearchCV(estimator=rf, param_grid=param_grid, cv=3, n_jobs=-1, verbose=2, scoring='f1_weighted')\n",
    "\n",
    "# Paso 4: División de los datos\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_balanced, y_balanced, test_size=0.2, random_state=42)\n",
    "\n",
    "# Paso 5: Entrenamiento del modelo con la búsqueda de cuadrícula\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Paso 6: Mejor modelo y predicción\n",
    "best_model = grid_search.best_estimator_\n",
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "# Paso 7: Reporte de resultados\n",
    "print(\"Mejores parámetros encontrados:\", grid_search.best_params_)\n",
    "print(\"Reporte de Clasificación:\\n\", classification_report(y_test, y_pred))\n",
    "print(\"Matriz de Confusión:\\n\", confusion_matrix(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "eab86ead-69b6-4a63-8197-7cd04c95a791",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Expected n_neighbors <= n_samples_fit, but n_neighbors = 6, n_samples_fit = 2, n_samples = 2",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[23], line 8\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# Genera datos sintéticos usando SMOTE para balanceo\u001b[39;00m\n\u001b[0;32m      7\u001b[0m smote \u001b[38;5;241m=\u001b[39m SMOTE(random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n\u001b[1;32m----> 8\u001b[0m X_balanced, y_balanced \u001b[38;5;241m=\u001b[39m \u001b[43msmote\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_resample\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_complejo\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_complejo\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m# Parámetros para búsqueda en cuadrícula\u001b[39;00m\n\u001b[0;32m     11\u001b[0m param_grid \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m     12\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mn_estimators\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;241m50\u001b[39m, \u001b[38;5;241m100\u001b[39m], \n\u001b[0;32m     13\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmax_depth\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m10\u001b[39m, \u001b[38;5;241m20\u001b[39m], \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     16\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mclass_weight\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbalanced\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m     17\u001b[0m }\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\imblearn\\base.py:208\u001b[0m, in \u001b[0;36mBaseSampler.fit_resample\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    187\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Resample the dataset.\u001b[39;00m\n\u001b[0;32m    188\u001b[0m \n\u001b[0;32m    189\u001b[0m \u001b[38;5;124;03mParameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    205\u001b[0m \u001b[38;5;124;03m    The corresponding label of `X_resampled`.\u001b[39;00m\n\u001b[0;32m    206\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    207\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m--> 208\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_resample\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\imblearn\\base.py:112\u001b[0m, in \u001b[0;36mSamplerMixin.fit_resample\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    106\u001b[0m X, y, binarize_y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_X_y(X, y)\n\u001b[0;32m    108\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msampling_strategy_ \u001b[38;5;241m=\u001b[39m check_sampling_strategy(\n\u001b[0;32m    109\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msampling_strategy, y, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampling_type\n\u001b[0;32m    110\u001b[0m )\n\u001b[1;32m--> 112\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit_resample\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    114\u001b[0m y_ \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    115\u001b[0m     label_binarize(output[\u001b[38;5;241m1\u001b[39m], classes\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39munique(y)) \u001b[38;5;28;01mif\u001b[39;00m binarize_y \u001b[38;5;28;01melse\u001b[39;00m output[\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m    116\u001b[0m )\n\u001b[0;32m    118\u001b[0m X_, y_ \u001b[38;5;241m=\u001b[39m arrays_transformer\u001b[38;5;241m.\u001b[39mtransform(output[\u001b[38;5;241m0\u001b[39m], y_)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\imblearn\\over_sampling\\_smote\\base.py:389\u001b[0m, in \u001b[0;36mSMOTE._fit_resample\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    386\u001b[0m X_class \u001b[38;5;241m=\u001b[39m _safe_indexing(X, target_class_indices)\n\u001b[0;32m    388\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnn_k_\u001b[38;5;241m.\u001b[39mfit(X_class)\n\u001b[1;32m--> 389\u001b[0m nns \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnn_k_\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkneighbors\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_class\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_distance\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m[:, \u001b[38;5;241m1\u001b[39m:]\n\u001b[0;32m    390\u001b[0m X_new, y_new \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_samples(\n\u001b[0;32m    391\u001b[0m     X_class, y\u001b[38;5;241m.\u001b[39mdtype, class_sample, X_class, nns, n_samples, \u001b[38;5;241m1.0\u001b[39m\n\u001b[0;32m    392\u001b[0m )\n\u001b[0;32m    393\u001b[0m X_resampled\u001b[38;5;241m.\u001b[39mappend(X_new)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:834\u001b[0m, in \u001b[0;36mKNeighborsMixin.kneighbors\u001b[1;34m(self, X, n_neighbors, return_distance)\u001b[0m\n\u001b[0;32m    832\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    833\u001b[0m         inequality_str \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mn_neighbors <= n_samples_fit\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m--> 834\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    835\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected \u001b[39m\u001b[38;5;132;01m{\u001b[39;00minequality_str\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, but \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    836\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mn_neighbors = \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mn_neighbors\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, n_samples_fit = \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mn_samples_fit\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    837\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mn_samples = \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mX\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m  \u001b[38;5;66;03m# include n_samples for common tests\u001b[39;00m\n\u001b[0;32m    838\u001b[0m     )\n\u001b[0;32m    840\u001b[0m n_jobs \u001b[38;5;241m=\u001b[39m effective_n_jobs(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_jobs)\n\u001b[0;32m    841\u001b[0m chunked_results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: Expected n_neighbors <= n_samples_fit, but n_neighbors = 6, n_samples_fit = 2, n_samples = 2"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# Genera datos sintéticos usando SMOTE para balanceo\n",
    "smote = SMOTE(random_state=42)\n",
    "X_balanced, y_balanced = smote.fit_resample(X_complejo, y_complejo)\n",
    "\n",
    "# Parámetros para búsqueda en cuadrícula\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100], \n",
    "    'max_depth': [None, 10, 20], \n",
    "    'min_samples_split': [5, 10],  \n",
    "    'min_samples_leaf': [1, 2],\n",
    "    'class_weight': ['balanced']\n",
    "}\n",
    "\n",
    "# Configuración del clasificador RandomForest con búsqueda de cuadrícula\n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "grid_search = GridSearchCV(estimator=rf, param_grid=param_grid, cv=3, n_jobs=-1, verbose=2, scoring='f1_weighted')\n",
    "\n",
    "# División de los datos en entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_balanced, y_balanced, test_size=0.2, random_state=42)\n",
    "\n",
    "# Entrena con la búsqueda de cuadrícula\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Mejor modelo encontrado\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "# Predicción en los datos de prueba\n",
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "# Muestra el reporte de clasificación y la matriz de confusión\n",
    "print(\"Mejores parámetros encontrados:\", grid_search.best_params_)\n",
    "print(\"Reporte de Clasificación:\\n\", classification_report(y_test, y_pred))\n",
    "print(\"Matriz de Confusión:\\n\", confusion_matrix(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "533774ac-de14-4331-afa1-bcaf00051052",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Expected n_neighbors <= n_samples_fit, but n_neighbors = 2, n_samples_fit = 1, n_samples = 1",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[24], line 8\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# Genera datos sintéticos usando SMOTE con k_neighbors reducido\u001b[39;00m\n\u001b[0;32m      7\u001b[0m smote \u001b[38;5;241m=\u001b[39m SMOTE(random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m, k_neighbors\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m----> 8\u001b[0m X_balanced, y_balanced \u001b[38;5;241m=\u001b[39m \u001b[43msmote\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_resample\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_complejo\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_complejo\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m# Parámetros para búsqueda en cuadrícula\u001b[39;00m\n\u001b[0;32m     11\u001b[0m param_grid \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m     12\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mn_estimators\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;241m50\u001b[39m, \u001b[38;5;241m100\u001b[39m], \n\u001b[0;32m     13\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmax_depth\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m10\u001b[39m, \u001b[38;5;241m20\u001b[39m], \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     16\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mclass_weight\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbalanced\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m     17\u001b[0m }\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\imblearn\\base.py:208\u001b[0m, in \u001b[0;36mBaseSampler.fit_resample\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    187\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Resample the dataset.\u001b[39;00m\n\u001b[0;32m    188\u001b[0m \n\u001b[0;32m    189\u001b[0m \u001b[38;5;124;03mParameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    205\u001b[0m \u001b[38;5;124;03m    The corresponding label of `X_resampled`.\u001b[39;00m\n\u001b[0;32m    206\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    207\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m--> 208\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_resample\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\imblearn\\base.py:112\u001b[0m, in \u001b[0;36mSamplerMixin.fit_resample\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    106\u001b[0m X, y, binarize_y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_X_y(X, y)\n\u001b[0;32m    108\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msampling_strategy_ \u001b[38;5;241m=\u001b[39m check_sampling_strategy(\n\u001b[0;32m    109\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msampling_strategy, y, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampling_type\n\u001b[0;32m    110\u001b[0m )\n\u001b[1;32m--> 112\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit_resample\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    114\u001b[0m y_ \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    115\u001b[0m     label_binarize(output[\u001b[38;5;241m1\u001b[39m], classes\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39munique(y)) \u001b[38;5;28;01mif\u001b[39;00m binarize_y \u001b[38;5;28;01melse\u001b[39;00m output[\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m    116\u001b[0m )\n\u001b[0;32m    118\u001b[0m X_, y_ \u001b[38;5;241m=\u001b[39m arrays_transformer\u001b[38;5;241m.\u001b[39mtransform(output[\u001b[38;5;241m0\u001b[39m], y_)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\imblearn\\over_sampling\\_smote\\base.py:389\u001b[0m, in \u001b[0;36mSMOTE._fit_resample\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    386\u001b[0m X_class \u001b[38;5;241m=\u001b[39m _safe_indexing(X, target_class_indices)\n\u001b[0;32m    388\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnn_k_\u001b[38;5;241m.\u001b[39mfit(X_class)\n\u001b[1;32m--> 389\u001b[0m nns \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnn_k_\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkneighbors\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_class\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_distance\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m[:, \u001b[38;5;241m1\u001b[39m:]\n\u001b[0;32m    390\u001b[0m X_new, y_new \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_samples(\n\u001b[0;32m    391\u001b[0m     X_class, y\u001b[38;5;241m.\u001b[39mdtype, class_sample, X_class, nns, n_samples, \u001b[38;5;241m1.0\u001b[39m\n\u001b[0;32m    392\u001b[0m )\n\u001b[0;32m    393\u001b[0m X_resampled\u001b[38;5;241m.\u001b[39mappend(X_new)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:834\u001b[0m, in \u001b[0;36mKNeighborsMixin.kneighbors\u001b[1;34m(self, X, n_neighbors, return_distance)\u001b[0m\n\u001b[0;32m    832\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    833\u001b[0m         inequality_str \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mn_neighbors <= n_samples_fit\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m--> 834\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    835\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected \u001b[39m\u001b[38;5;132;01m{\u001b[39;00minequality_str\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, but \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    836\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mn_neighbors = \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mn_neighbors\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, n_samples_fit = \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mn_samples_fit\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    837\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mn_samples = \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mX\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m  \u001b[38;5;66;03m# include n_samples for common tests\u001b[39;00m\n\u001b[0;32m    838\u001b[0m     )\n\u001b[0;32m    840\u001b[0m n_jobs \u001b[38;5;241m=\u001b[39m effective_n_jobs(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_jobs)\n\u001b[0;32m    841\u001b[0m chunked_results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: Expected n_neighbors <= n_samples_fit, but n_neighbors = 2, n_samples_fit = 1, n_samples = 1"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# Genera datos sintéticos usando SMOTE con k_neighbors reducido\n",
    "smote = SMOTE(random_state=42, k_neighbors=1)\n",
    "X_balanced, y_balanced = smote.fit_resample(X_complejo, y_complejo)\n",
    "\n",
    "# Parámetros para búsqueda en cuadrícula\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100], \n",
    "    'max_depth': [None, 10, 20], \n",
    "    'min_samples_split': [5, 10],  \n",
    "    'min_samples_leaf': [1, 2],\n",
    "    'class_weight': ['balanced']\n",
    "}\n",
    "\n",
    "# Configuración del clasificador RandomForest con búsqueda de cuadrícula\n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "grid_search = GridSearchCV(estimator=rf, param_grid=param_grid, cv=3, n_jobs=-1, verbose=2, scoring='f1_weighted')\n",
    "\n",
    "# División de los datos en entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_balanced, y_balanced, test_size=0.2, random_state=42)\n",
    "\n",
    "# Entrena con la búsqueda de cuadrícula\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Mejor modelo encontrado\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "# Predicción en los datos de prueba\n",
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "# Muestra el reporte de clasificación y la matriz de confusión\n",
    "print(\"Mejores parámetros encontrados:\", grid_search.best_params_)\n",
    "print(\"Reporte de Clasificación:\\n\", classification_report(y_test, y_pred))\n",
    "print(\"Matriz de Confusión:\\n\", confusion_matrix(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4114489e-aa82-43f3-a540-10bf05d27a8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 24 candidates, totalling 72 fits\n",
      "Mejores parámetros encontrados: {'class_weight': 'balanced', 'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 5, 'n_estimators': 50}\n",
      "Reporte de Clasificación:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         0\n",
      "           2       0.00      0.00      0.00         0\n",
      "           3       0.00      0.00      0.00         1\n",
      "           4       0.00      0.00      0.00         1\n",
      "           5       0.00      0.00      0.00         3\n",
      "           6       0.00      0.00      0.00         2\n",
      "           7       0.17      1.00      0.29         1\n",
      "           8       0.17      0.33      0.22         3\n",
      "           9       0.67      1.00      0.80         2\n",
      "          10       0.00      0.00      0.00         1\n",
      "          12       0.00      0.00      0.00         2\n",
      "          13       1.00      1.00      1.00         2\n",
      "          14       0.50      0.50      0.50         4\n",
      "          15       0.00      0.00      0.00         1\n",
      "          16       0.20      1.00      0.33         1\n",
      "          17       0.00      0.00      0.00         3\n",
      "          18       0.33      1.00      0.50         1\n",
      "          19       0.00      0.00      0.00         0\n",
      "          20       0.00      0.00      0.00         1\n",
      "          21       1.00      0.50      0.67         2\n",
      "          22       0.00      0.00      0.00         1\n",
      "          23       0.20      1.00      0.33         1\n",
      "          24       0.50      1.00      0.67         1\n",
      "          25       0.00      0.00      0.00         2\n",
      "          26       0.00      0.00      0.00         5\n",
      "          27       0.00      0.00      0.00         2\n",
      "          28       0.50      1.00      0.67         2\n",
      "          29       0.67      1.00      0.80         2\n",
      "          30       0.00      0.00      0.00         2\n",
      "          31       0.00      0.00      0.00         1\n",
      "          32       0.00      0.00      0.00         2\n",
      "          33       0.00      0.00      0.00         2\n",
      "          34       0.25      1.00      0.40         1\n",
      "          35       0.00      0.00      0.00         1\n",
      "          36       0.00      0.00      0.00         2\n",
      "          37       0.00      0.00      0.00         3\n",
      "          38       0.00      0.00      0.00         1\n",
      "          39       0.00      0.00      0.00         2\n",
      "          40       0.00      0.00      0.00         1\n",
      "          41       0.00      0.00      0.00         5\n",
      "          42       0.20      0.50      0.29         2\n",
      "          43       0.00      0.00      0.00         1\n",
      "          44       0.20      0.50      0.29         2\n",
      "          45       1.00      0.33      0.50         6\n",
      "\n",
      "    accuracy                           0.27        81\n",
      "   macro avg       0.17      0.29      0.19        81\n",
      "weighted avg       0.23      0.27      0.21        81\n",
      "\n",
      "Matriz de Confusión:\n",
      " [[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 1 0]\n",
      " [0 0 0 ... 0 0 2]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\famag\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\famag\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\famag\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\famag\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\famag\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\famag\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# Genera datos balanceados usando RandomOverSampler\n",
    "ros = RandomOverSampler(random_state=42)\n",
    "X_balanced, y_balanced = ros.fit_resample(X_complejo, y_complejo)\n",
    "\n",
    "# Parámetros para búsqueda en cuadrícula\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100], \n",
    "    'max_depth': [None, 10, 20], \n",
    "    'min_samples_split': [5, 10],  \n",
    "    'min_samples_leaf': [1, 2],\n",
    "    'class_weight': ['balanced']\n",
    "}\n",
    "\n",
    "# Configuración del clasificador RandomForest con búsqueda de cuadrícula\n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "grid_search = GridSearchCV(estimator=rf, param_grid=param_grid, cv=3, n_jobs=-1, verbose=2, scoring='f1_weighted')\n",
    "\n",
    "# División de los datos en entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_balanced, y_balanced, test_size=0.2, random_state=42)\n",
    "\n",
    "# Entrena con la búsqueda de cuadrícula\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Mejor modelo encontrado\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "# Predicción en los datos de prueba\n",
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "# Muestra el reporte de clasificación y la matriz de confusión\n",
    "print(\"Mejores parámetros encontrados:\", grid_search.best_params_)\n",
    "print(\"Reporte de Clasificación:\\n\", classification_report(y_test, y_pred))\n",
    "print(\"Matriz de Confusión:\\n\", confusion_matrix(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f4280f79-14c7-41d4-86a8-de232da3c384",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mejores parámetros: {'class_weight': 'balanced', 'max_depth': None, 'min_samples_split': 5, 'n_estimators': 100}\n",
      "Reporte de Clasificación:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.37      0.39      0.38        18\n",
      "           1       0.48      0.45      0.47        22\n",
      "\n",
      "    accuracy                           0.42        40\n",
      "   macro avg       0.42      0.42      0.42        40\n",
      "weighted avg       0.43      0.42      0.43        40\n",
      "\n",
      "Matriz de Confusión:\n",
      " [[ 7 11]\n",
      " [12 10]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "\n",
    "# Mapear etiquetas a binario\n",
    "def map_to_binary(priority):\n",
    "    return 1 if priority >= threshold else 0\n",
    "\n",
    "# Define el umbral para \"alta\" urgencia (ajusta según convenga)\n",
    "threshold = 25\n",
    "y_complejo_binario = [map_to_binary(priority) for priority in y_complejo]\n",
    "\n",
    "# Balanceo de clases\n",
    "ros = RandomOverSampler(random_state=42)\n",
    "X_balanced, y_balanced = ros.fit_resample(X_complejo, y_complejo_binario)\n",
    "\n",
    "# División de datos y búsqueda de hiperparámetros\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_balanced, y_balanced, test_size=0.2, random_state=42)\n",
    "param_grid = {'n_estimators': [50, 100], 'max_depth': [None, 10, 20], 'min_samples_split': [5, 10], 'class_weight': ['balanced']}\n",
    "grid_search = GridSearchCV(RandomForestClassifier(random_state=42), param_grid, cv=3, n_jobs=-1, scoring='f1')\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Modelo optimizado\n",
    "best_model = grid_search.best_estimator_\n",
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "# Resultados\n",
    "print(\"Mejores parámetros:\", grid_search.best_params_)\n",
    "print(\"Reporte de Clasificación:\\n\", classification_report(y_test, y_pred))\n",
    "print(\"Matriz de Confusión:\\n\", confusion_matrix(y_test, y_pred))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
