{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f7ea16d9-0598-4ab6-a26d-587053a319e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distribución de clases para umbral 5: {0: 143, 1: 57}\n",
      "Entrenando modelo con umbral 5.\n",
      "\n",
      "Resultados para umbral = 5\n",
      "Mejores parámetros: {'n_estimators': 150, 'min_samples_split': 10, 'min_samples_leaf': 1, 'max_depth': 15, 'class_weight': 'balanced'}\n",
      "Reporte de Clasificación:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        27\n",
      "           1       1.00      1.00      1.00        31\n",
      "\n",
      "    accuracy                           1.00        58\n",
      "   macro avg       1.00      1.00      1.00        58\n",
      "weighted avg       1.00      1.00      1.00        58\n",
      "\n",
      "Matriz de Confusión:\n",
      " [[27  0]\n",
      " [ 0 31]]\n",
      "\n",
      "==================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "\n",
    "# Carga de datos\n",
    "data = pd.read_csv('conjunto_datos_tareas_complejo.csv')\n",
    "X_complejo = data[['urgencia', 'importancia', 'prioridad_externa', 'bloqueo', \n",
    "                   'impacto_en_otros', 'valor_agregado', 'responsabilidad', 'dias_restantes']].values\n",
    "y_complejo = data['urgencia'].values  # Usamos 'urgencia' para la clasificación binaria\n",
    "\n",
    "# Función para mapear urgencia a binario según un umbral\n",
    "def map_to_binary(priority, threshold=25):\n",
    "    return 1 if priority >= threshold else 0\n",
    "\n",
    "# Probar con diferentes umbrales\n",
    "thresholds = [5, 10, 15, 20, 25]\n",
    "for threshold in thresholds:\n",
    "    y_complejo_binario = [map_to_binary(priority, threshold) for priority in y_complejo]\n",
    "    \n",
    "    # Verificar distribución de clases\n",
    "    unique, counts = np.unique(y_complejo_binario, return_counts=True)\n",
    "    print(f\"Distribución de clases para umbral {threshold}: {dict(zip(unique, counts))}\")\n",
    "    \n",
    "    if len(unique) > 1:  # Continuar solo si hay más de una clase\n",
    "        print(f\"Entrenando modelo con umbral {threshold}.\\n\")\n",
    "        \n",
    "        # Balanceo de clases\n",
    "        ros = RandomOverSampler(random_state=42)\n",
    "        X_balanced, y_balanced = ros.fit_resample(X_complejo, y_complejo_binario)\n",
    "\n",
    "        # División de datos\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X_balanced, y_balanced, test_size=0.2, random_state=42)\n",
    "\n",
    "        # Configuración de búsqueda de hiperparámetros\n",
    "        param_dist = {\n",
    "            'n_estimators': [50, 100, 150],\n",
    "            'max_depth': [10, 15, 20],\n",
    "            'min_samples_split': [5, 10],\n",
    "            'min_samples_leaf': [1, 2, 3],\n",
    "            'class_weight': [None, 'balanced']\n",
    "        }\n",
    "\n",
    "        # Búsqueda aleatoria con RandomizedSearchCV\n",
    "        rf = RandomForestClassifier(random_state=42)\n",
    "        random_search = RandomizedSearchCV(rf, param_distributions=param_dist, n_iter=20, cv=3, n_jobs=-1, scoring='f1', random_state=42)\n",
    "        random_search.fit(X_train, y_train)\n",
    "\n",
    "        # Evaluación del modelo\n",
    "        best_model = random_search.best_estimator_\n",
    "        y_pred = best_model.predict(X_test)\n",
    "\n",
    "        # Mostrar resultados\n",
    "        print(f\"Resultados para umbral = {threshold}\")\n",
    "        print(\"Mejores parámetros:\", random_search.best_params_)\n",
    "        print(\"Reporte de Clasificación:\\n\", classification_report(y_test, y_pred))\n",
    "        print(\"Matriz de Confusión:\\n\", confusion_matrix(y_test, y_pred))\n",
    "        print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "        \n",
    "        break  # Salir del bucle si encuentra un umbral adecuado\n",
    "    else:\n",
    "        print(f\"Umbral {threshold} no es adecuado, probando otro.\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b4b1a58c-3fce-4ad9-b2c1-3dc46e34e3b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resultados de F1 por pliegue: [1. 1. 1. 1. 1.]\n",
      "Promedio de F1 en 5 pliegues: 1.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Definir el clasificador con los mejores parámetros encontrados\n",
    "rf_best = RandomForestClassifier(\n",
    "    n_estimators=150, \n",
    "    min_samples_split=10, \n",
    "    min_samples_leaf=1, \n",
    "    max_depth=15, \n",
    "    class_weight='balanced', \n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Ejecutar validación cruzada de 5 pliegues\n",
    "scores = cross_val_score(rf_best, X_balanced, y_balanced, cv=5, scoring='f1')\n",
    "\n",
    "# Mostrar los resultados de cada pliegue y el promedio\n",
    "print(\"Resultados de F1 por pliegue:\", scores)\n",
    "print(\"Promedio de F1 en 5 pliegues:\", scores.mean())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fae54c22-5fef-4f05-a00b-cb6f9e90616e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mejores parámetros (menor complejidad): {'n_estimators': 100, 'min_samples_split': 15, 'min_samples_leaf': 2, 'max_depth': 12, 'class_weight': 'balanced'}\n",
      "Resultados de F1 por pliegue con menor complejidad: [1. 1. 1. 1. 1.]\n",
      "Promedio de F1 en 5 pliegues (menor complejidad): 1.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Definir el rango de hiperparámetros ajustados para reducir la complejidad\n",
    "param_dist = {\n",
    "    'n_estimators': [50, 100],\n",
    "    'max_depth': [10, 12],\n",
    "    'min_samples_split': [15, 20],\n",
    "    'min_samples_leaf': [2, 3],\n",
    "    'class_weight': ['balanced']\n",
    "}\n",
    "\n",
    "# Ejecutar RandomizedSearchCV con los nuevos parámetros de menor complejidad\n",
    "rf_simple = RandomForestClassifier(random_state=42)\n",
    "random_search_simple = RandomizedSearchCV(\n",
    "    rf_simple, param_distributions=param_dist, n_iter=10, cv=3, n_jobs=-1, scoring='f1'\n",
    ")\n",
    "random_search_simple.fit(X_balanced, y_balanced)\n",
    "\n",
    "# Evaluar el mejor modelo encontrado\n",
    "best_model_simple = random_search_simple.best_estimator_\n",
    "\n",
    "# Validación cruzada con el modelo de menor complejidad\n",
    "scores_simple = cross_val_score(best_model_simple, X_balanced, y_balanced, cv=5, scoring='f1')\n",
    "\n",
    "# Mostrar resultados\n",
    "print(\"Mejores parámetros (menor complejidad):\", random_search_simple.best_params_)\n",
    "print(\"Resultados de F1 por pliegue con menor complejidad:\", scores_simple)\n",
    "print(\"Promedio de F1 en 5 pliegues (menor complejidad):\", scores_simple.mean())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "12ceda28-6ee8-4b75-8994-372985927df3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reporte de Clasificación en Conjunto de Prueba:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        27\n",
      "           1       1.00      1.00      1.00        31\n",
      "\n",
      "    accuracy                           1.00        58\n",
      "   macro avg       1.00      1.00      1.00        58\n",
      "weighted avg       1.00      1.00      1.00        58\n",
      "\n",
      "Matriz de Confusión en Conjunto de Prueba:\n",
      " [[27  0]\n",
      " [ 0 31]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# División en entrenamiento+validación y prueba (80%-20%)\n",
    "X_train_val, X_test_final, y_train_val, y_test_final = train_test_split(X_balanced, y_balanced, test_size=0.2, random_state=42)\n",
    "\n",
    "# Definir el modelo con los mejores parámetros encontrados\n",
    "rf_best_simple = RandomForestClassifier(\n",
    "    n_estimators=100,\n",
    "    min_samples_split=15,\n",
    "    min_samples_leaf=2,\n",
    "    max_depth=12,\n",
    "    class_weight='balanced',\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Entrenar el modelo en el conjunto de entrenamiento+validación\n",
    "rf_best_simple.fit(X_train_val, y_train_val)\n",
    "\n",
    "# Evaluar en el conjunto de prueba\n",
    "y_pred_final = rf_best_simple.predict(X_test_final)\n",
    "\n",
    "# Mostrar resultados en el conjunto de prueba\n",
    "print(\"Reporte de Clasificación en Conjunto de Prueba:\\n\", classification_report(y_test_final, y_pred_final))\n",
    "print(\"Matriz de Confusión en Conjunto de Prueba:\\n\", confusion_matrix(y_test_final, y_pred_final))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b32baab7-65e4-4841-90ea-ad618b3344ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['modelo_clasificacion_tareas.pkl']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "# Guarda el modelo en un archivo\n",
    "joblib.dump(best_model, 'modelo_clasificacion_tareas.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0697ce57-e6a4-45c9-9778-eeed8dd33b17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['modelo_clasificacion_tareas.pkl']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "# Suponiendo que `best_model` es tu modelo entrenado y optimizado\n",
    "joblib.dump(best_model, 'modelo_clasificacion_tareas.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
